---
title: "Практическое задание №3"
author: "Журавлева Юлия БИСО-01-20"
format:   
  md:
    output-file: README.md
---

# Анализ данных сетевого трафика при помощи библиотеки Arrow

## Цель работы

1. Изучить возможности технологии Apache Arrow для обработки и анализ больших данных
2. Получить навыки применения Arrow совместно с языком программирования R
3. Получить навыки анализа метаинфомации о сетевом трафике
4. Получить навыки применения облачных технологий хранения, подготовки и анализа данных: Yandex Object Storage, Rstudio Server.

## Исходные данные

1. Ноутбук с ОС Windows 10
2. Apache Arrow
3. Yandex Object Storage
4. RStudio Server

## Задание

Используя язык программирования R, библиотеку arrow и облачную `IDE Rstudio Server`, развернутую в `Yandex Cloud`, выполнить задания и составить отчет.

## Ход работы

### 1. Настройка подключения к IDE Rstudio Server через ssh-туннель

- Подключимся к удалённому серверу через ssh-туннель как пользователь user18. 

```{}
PS C:\Users\Юлия> ssh -i "C:\Users\\Downloads\Telegram Desktop\rstudio.key" -L 8787:127.0.0.1:8787 user18@62.84.123.211
```

![](screen/1.png)

- Поменяем пароль с дефолтного на персональный. Скриншот предоставлен с системы Kali Linux, так как первоначальная настройка была именно на нём, но из-за возникших проблем на ВМ, пришлось перейти на основную систему Windows.

![](screen/2.png)

- Перейдём по адресу `http://127.0.0.1:8787` и зайдём под созданным пользователем `user18`.

![](screen/3.png)

- Настроим Git на RStudio Server с помощью SSH ключа. Так как изначально установка была на ОС Kali Linux, то повторной аутентификации на ОС Windows не потребовалось. 

![](screen/4.png)

Однако этого оказалось недостаточно для пуша в репозиторий, поэтому после танцев с бубном, спасение нашлось в индивидуальном токене пользователя на замену аутентификации по паролю.

![](screen/5.png)

### 2. Настройка рабочего пространства

- Первым делом установим необходимые библиотеки

```{r}
library(arrow)
library(tidyverse)
library(dplyr)
```

- Далее создаем директорию dataset и загружаем в нее dataframe arrow-datasets/tm_data.pqt из Yandex Object Storage.

```{r}
dir.create("dataset")

curl::multi_download("https://storage.yandexcloud.net/arrow-datasets/tm_data.pqt", "dataset/ya_dt.pqt",
  resume = TRUE
)
```

- Посмотрим содержимое нашего датасета, чтобы убедиться, что он работает.

```{r}
full_df <- arrow::open_dataset(sources = "dataset/ya_dt.pqt", format  = "parquet")
full_df %>% glimpse()
```

- Заметим, что с полем `timestamp` что-то не так, а именно указан неверный тип данных. Приведём его в более понятный вид.

```{r}
full_df <- full_df %>% mutate(timestamp = as_datetime(timestamp / 1000, origin = "1970-01-01", tz = "UTC"))
full_df %>% glimpse()
```

## Обработка данных

### Задание 1: Найдите утечку данных из Вашей сети

***Поставленная задача***

Важнейшие документы с результатами нашей исследовательской деятельности в области создания вакцин скачиваются в виде больших заархивированных дампов. Один из хостов в нашей сети используется для пересылки этой информации – он пересылает гораздо больше информации на внешние ресурсы в Интернете, чем остальные компьютеры нашей сети. Определите его IP-адрес.

- Для начала определим IP адреса внутренней сети, которые начинаются с 12-14 октетов.

```{r}
df_inside <- full_df %>%
  filter(str_detect(src, "^1[2-4].")) %>%
  filter(!str_detect(dst, "^1[2-4]."))
```

- Используя отфильтрованные данные внутреннего трафика, сгрупируем по IP-адресу источника и просуммируем его общее количество байтов. Выведем на экран итоговые значения источика с наибольшим количеством байтов.

```{r}
sus_host <- df_inside %>% group_by(src) %>% 
  summarise(ins_sum = sum(bytes)) %>% arrange(desc(ins_sum)) %>% collect()

sus_host_1 <- sus_host %>% slice(1)

cat("IP-адрес подозрительного хоста:", sus_host_1$src, "\n", 
    "Сумма затраченного трафика (байт)", format(sus_host_1$ins_sum, scientific = FALSE))
```

### Задание 2: Найдите утечку данных 2

***Поставленная задача***

Другой атакующий установил автоматическую задачу в системном планировщике `cron` для экспорта содержимого внутренней wiki системы. Эта система генерирует большое количество трафика в нерабочие часы, больше чем остальные хосты. Определите IP этой системы. Известно, что ее IP адрес отличается от нарушителя из предыдущей задачи.

- Для начала посчитаем по известным часам сумму трафика.

```{r}
hours <- full_df %>% group_by(hour(timestamp)) %>%
  summarise(ins_sum_2 = sum(bytes)) %>% arrange(desc(ins_sum_2)) %>% collect()

hours %>% head(10)
```

- Заметим, что самое большое количество трафика затрачивается с 16 до 23, что может указать нам на работу автоматической задачи. Известно, что искомый IP адрес отличается от нарушителей из предыдущих задач, поэтому сразу добавим его в исключения фильтрации. Найдём новый IP-адрес нарушителя по максимальному объёму затраченного трафика.

```{r}
sus_cron <- df_inside %>% filter(!str_detect(src, "^13.37.84.125$")) %>%
  filter(hour(timestamp) < 16 | hour(timestamp) > 23) %>% group_by(src) %>%
  summarise(ins_sum = sum(bytes)) %>% arrange(desc(ins_sum)) %>% collect()

sus_cron_1 <- sus_cron %>% slice(1)

cat("IP-адрес подозрительного хоста:", sus_cron_1$src, "\n", 
    "Сумма затраченного трафика (байт):", format(sus_cron_1$ins_sum, scientific = FALSE))
```

### Задание 3: Найдите утечку данных 3

***Поставленная задача***

Еще один нарушитель собирает содержимое электронной почты и отправляет в Интернет используя порт, который обычно используется для другого типа трафика. Атакующий пересылает большое количество информации используя этот порт, которое не характерно для других хостов, использующих этот номер порта. Определите IP этой системы. Известно, что ее IP адрес отличается от нарушителей из предыдущих задач.

- Создадим новый датафрейм, куда занесём исключения в виде адресов, которые соответствуют ответам 1 и 2 задания. 

```{r}
df_inside_new <- df_inside %>% filter(!(str_detect(src, "^13.37.84.125") | str_detect(src, "^12.55.77.96"))) %>% collect()

df_inside_new %>% head(10)
```

- Сгруппируем трафик по портам и найдем те, для которых разница между максимальным и средним количеством переданных байтов максимальна, т.е. составляет > 170000 байт.

```{r}
diff_port <- df_inside_new %>% group_by(port) %>% 
  summarise(avg_port = mean(bytes), max_port = max(bytes), sum_port = sum(bytes)) %>% 
  mutate(dff_port = max_port - avg_port)  %>% filter(dff_port != 0, dff_port > 170000) %>%
  collect()

print(diff_port)
```

- Теперь, когда мы знаем порт (37), найдем IP-адреса отправителей, которые передали большое количество данных.

```{r}
sus_port <- df_inside_new %>% filter(port == 37) %>% group_by(src) %>%
  summarise(sum_port_2 = sum(bytes)) %>% arrange(desc(sum_port_2)) %>% collect()

sus_port %>% head(10)

sus_port_1 <- sus_port %>% head(1)

cat("IP-адрес подозрительного хоста:", sus_port_1$src, "\n", 
    "Сумма затраченного трафика (байт):", format(sus_port_1$sum_port_2, scientific = FALSE))

```

## Оценка результата

С помощью `RStudio Server` и `Apache Arrow` удалось освоить использование облачных технологий, а также познакомиться с функционалом данных сервисов и применить их возможности для выполнения поставленных задач. 

## Вывод

Для решения данных задач были применены навыки анализа метаинформации сетевого трафика и получить практические знания в применении облачных технологий для хранения, подготовки и анализа данных.  